[Toc]

## 各种相机用在SLAM上的特点
### 单目相机 (Monocular Camera)
- 结构简单，成本低
- 记录了场景在相机成像平面上的投影，以二维的形式记录了三维的世界
- 丢掉了深度信息，很难通过单张图片计算距离

#### 恢复三维结构
- 需要移动单目相机才能估计物体的运动
- **结构 (Structure)**: 场景中物体的远近和大小
- **视差 (Disparity)**: 近处的物体移动快，远处（无穷远处）物体静止不动

> 通过视差估计出来的物体远近是一个相对值，如果把相机运动和场景大小同时缩小两倍，相机看到的成像都是一样的。单目SLAM无法仅凭图像确定估计到的轨迹和地图与真实值相差的尺度，即具有**尺度不确定性**

### 双目相机 (Stereo Camera) 和深度相机 (RGB-D Camera)
#### 双目相机
- 两个相机之间的距离称为**基线（Baseline）**
- 需要**大量的计算**才能（不太可靠地）估计每一个像素点的距离。基线距离越大，能够测量到的范围就越远
- 标定和配置比较复杂，精度受分辨率限制
- 往往需要GPU和FPGA的加速才能实时输出整张深度图。

#### 深度相机
- 红外结构光或飞行时间 (Time-of-Flight, TOF)，通过物理测量手段主动测量物体与相机之间的距离
- 主要用于室内，室外很难应用

## 经典视觉SLAM框架
<div align="center">
<img src=../resources/027.png width=80% />
</div>

- **传感器数据读取**：在视觉SLAM中主要为相机图像的获取和预处理
- **前端视觉里程计 (Visual Odometry, VO)**：估算相邻图像间相机的运动，以及局部地图的样子，又称前端(Frontend)
- **后端非线性优化 (Optimization)**：接受不同时刻视觉里程计测量的相机位姿，以及回环检测信息并进行优化，得到**全局一致**的轨迹和地图，称为后端(Backend)
- **回环检测 (Loop Closure Detection)**：检测机器人是否到达先前到达过的位置
- **建图 (Mapping)**：根据估计的轨迹，建立任务要求对应的地图

> 在工作环境为静态、刚体、光照变化不明显，没有人为干扰的场景下，目前的SLAM技术已经相当成熟

### 视觉里程计
- 关心相邻图像之间相机的运动
- 是SLAM的关键问题
- 仅通过里程计来估计轨迹，会出现**累积漂移 (Accumulating Drift)**
- 前端与计算机视觉研究领域比较相关，比如**图像的特征提取和匹配**

### 后端优化
- 主要处理SLAM过程中的**噪声**问题
- 如何从带有噪声的数据中估计整个系统的状态（包括机器人自身的轨迹以及地图），以及状态估计的不确定程度有多大
- 后端主要利用**滤波**和**非线性优化算法**

> SLAM问题的本质就是一个状态估计问题，即**对运动物体自身和周围环境空间不确定性的估计**

### 回环检测
- 主要解决位置估计随时间漂移的问题
- 识别曾经到达的场景：一个计算图像间相似性的问题

### 建图
#### 度量地图
- **稀疏地图**：进行了一定程度的抽象，不需要表达所有物体
  - 选择一部分具有代表意义的东西，称为路标 (Landmark)
  - 定位时使用稀疏地图就足够了
- **稠密地图**：着重于建模所有看到的东西
  - 导航时往往需要用到稠密地图
  - 二维度量地图：用栅格(Grid)表示；三维度量地图：用体素格(Voxel)表示
    - 含有占据(Occupied)，空闲(Free)，未知(Unknow)三种状态
  - 可用于[A*](https://en.wikipedia.org/wiki/A*_search_algorithm), D*等导航算法
  - 缺点：需要耗费大量的存储空间，但在多数情况下地图的许多细节部分是无用的
#### 拓扑地图
- 图(Graph)，由节点(Node)和边(Edge)表示，只考虑节点间的连通性
- 放松了地图对精确程度的需要，不擅长表达具有复杂结构的地图

## SLAM问题的数学描述
- 运动：从$k-1$到$k$时刻，机器人的位置$x$是如何变化的
- 观测：$k$时刻机器人到达了一处地标$y_i$

### 运动方程
$$x_k=f(x_{k-1},u_k,w_k)\tag{1}$$
- $u_k$是运动传感器的读数或输入
- $w_k$是噪声，其存在使得这个模型成为了**随机模型**

### 观测方程
$$z_{k,j}=h(y_j,x_k,v_{k,j})\tag{2}$$
- 在$x_k$位置上看到路标点$y_j$时，产生了一个观测数据$z_{k,j}$
- $v_{k,j}$是噪声

### 参数化 (Pameterization)：
  - 以平面运动为例：位姿由两个位置和一个转角来描述$x_k=[x_1,x_2,\theta]^T_k$，输入指令假设为他们的变化量$u_k=[\Delta x_1,\Delta x_2,\Delta \theta]^T_k$
  - 具体化运动方程为
    - $$\left[\begin{matrix}x_1\\x_2\\\theta\end{matrix}\right]_k=\left[\begin{matrix}x_1\\x_2\\\theta\end{matrix}\right]_{k-1}+\left[\begin{matrix}\Delta x_1\\\Delta x_2\\\Delta\theta\end{matrix}\right]_k+w_k$$
  - 以机器人上携带激光传感器为例，测得路标与机器人本体的距离和夹角分别为$r$和$\phi$，可将观测方程写为
    - $$\left[\begin{matrix}r_{k,j}\\\phi_{k,j}\end{matrix}\right]=\left[\begin{matrix}\sqrt{(y_{1,j}-x_{1,k})^2+(y_{2,j}-x_{2,k})^2}\\\rm{arctan}(\frac{y_{2,j}-x_{2,k}}{y_{1,j}-x_{1,k}})\end{matrix}\right]+v$$
  
<div align="center">
<img src=../resources/028.png width=30% />
</div>

- 针对不同传感器，方程(1)和(2)具有不同的参数化方式
- SLAM过程可以总结为(1)和(2)两个方程
  - 当知道控制量$u$以及传感器的读数$z$时，求解定位问题（估计$x$）和建图问题（估计$y$）

### 状态估计问题的求解
- 运动和观测方程是否为线性？噪声是否服从高斯分布？
- **线性高斯系统（Linear Guassian, LG系统）** 的无偏最优估计可以由卡尔曼滤波给出（Kalman Filter, KF）
- **非线性非高斯系统（Non-Linear Non-Guassian, NLNG系统）** 一般会使用拓展卡尔曼滤波（Extended Kalman Filter, EKF）和非线性优化方法来求解